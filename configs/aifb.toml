# Dataset configuration context

# name of the dataset
name = "AIFB"

[graph]
# available at https://gitlab.com/wxwilcke/mmkg
context = "/data/projects/multimodal_datasets/aifb/aifb+.nt.gz"
train = "/data/projects/multimodal_datasets/aifb/aifb+_train_set.nt.gz"
valid = "/data/projects/multimodal_datasets/aifb/aifb+_valid_set.nt.gz"
test = "/data/projects/multimodal_datasets/aifb/aifb+_test_set.nt.gz"

[graph.structural]
include_inverse_properties = true
exclude_properties = []  # use empty list to include all
separate_literals = false
multiprocessing = false

[[graph.features]]
datatype = 'xsd.numeric'
include = true
share_weights = false
embedding_dim = 4
p_dropout = 0.0
gpu_acceleration = false
p_noise = 0.0
noise_multiplier = 0.0

[[graph.features]]
datatype = 'xsd.gYear'
include = true
share_weights = true
embedding_dim = 1
p_dropout = 0.0
gpu_acceleration = false
p_noise = 0.0
noise_multiplier = 0.0

[[graph.features]]
datatype = 'xsd.string'
include = true
share_weights = true
trim_outliers = false
remove_outliers = true
embedding_dim = 32
gpu_acceleration = false
p_dropout = 0.0
model = [ "huggingface/pytorch-transformers",
          "model",
          "distilbert-base-multilingual-cased" ]
tokenizer.config = [ "huggingface/pytorch-transformers",
                     "tokenizer",
                     "distilbert-base-multilingual-cased" ]
tokenizer.pad_token = "[PAD]"


[task]
type = "node classification"
target_property = 'http://swrc.ontoware.org/ontology#affiliation'
target_property_inv = 'http://swrc.ontoware.org/ontology#employs'
seed = -1  # use < 0 for random
gcn_gpu_acceleration = false
batchsize = -1  # < 0 for full batch
early_stopping.patience = -1
early_stopping.tolerance = 0.01

[model]
epoch = 50
learning_rate = 0.01
num_bases = 0
p_dropout = 0
weight_decay = 0.0
l1_lambda = 0.0
l2_lambda = 0.0
bias = false

[[model.layers]]
type = 'mrgcn'
hidden_nodes = 16

[[model.layers]]
type = 'mrgcn'

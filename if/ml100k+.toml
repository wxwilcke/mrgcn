# Dataset configuration context

# name of the dataset
name = "ML100k+"

[graph]
# available at https://gitlab.com/wxwilcke/mmkg
train = "../../datasets/movielens-100k\+/rdf/"
valid = "../../datasets/movielens-100k\+/rdf/"
test = "../../datasets/movielens-100k\+/rdf/"

[graph.structural]
include_inverse_properties = true
exclude_properties = []  # use empty list to include all
separate_literals = false
multiprocessing = false

[[graph.features]]
datatype = 'xsd.numeric'
include = true
share_weights = true
embedding_dim = 4
p_dropout = 0.0
p_noise = 0.0
noise_multiplier = 0.0

#[[graph.features]]
#datatype = 'xsd.boolean'
#include = true
#share_weights = true
#
#[[graph.features]]
#datatype = 'xsd.gYear'
#include = true
#share_weights = true
#
#[[graph.features]]
#datatype = 'xsd.date'
#include = true
#share_weights = true

[[graph.features]]
datatype = 'xsd.dateTime'
include = true
share_weights = true
embedding_dim = 3
p_dropout = 0.0
p_noise = 0.0
noise_multiplier = 0.0

[[graph.features]]
datatype = 'xsd.anyURI'
include = true
share_weights = true
trim_outliers = false
remove_outliers = false
embedding_dim = 16
p_dropout = 0.0
model = [ "huggingface/pytorch-transformers",
          "model",
          "distilbert-base-multilingual-cased" ]
tokenizer.config = [ "huggingface/pytorch-transformers",
                     "tokenizer",
                     "distilbert-base-multilingual-cased" ]
tokenizer.pad_token = "[PAD]"


[[graph.features]]
datatype = 'xsd.string'
include = true
share_weights = true
trim_outliers = false
remove_outliers = false
embedding_dim = 16
p_dropout = 0.0
model = [ "huggingface/pytorch-transformers",
          "model",
          "distilbert-base-multilingual-cased" ]
tokenizer.config = [ "huggingface/pytorch-transformers",
                     "tokenizer",
                     "distilbert-base-multilingual-cased" ]
tokenizer.pad_token = "[PAD]"


[[graph.features]]
datatype = 'blob.image'
include = true
share_weights = true
remove_outliers = false
embedding_dim = 128
p_dropout = 0.0
p_noise = 0.0
noise_multiplier = 0.0
model = [ "pytorch/vision:v0.10.0",
          "mobilenet_v2",
          "MobileNet_V2_Weights.IMAGENET1K_V1" ]
transform.mode = "RGB"
transform.interpolationMode = "BILINEAR"
transform.resizeSize = 232
transform.centerCrop = 224
transform.mean = [0.485, 0.456, 0.406]
transform.std = [0.229, 0.224, 0.225]

#[[graph.features]]
#datatype = 'ogc.wktLiteral'
#include = true
#num_batches = 16
#share_weights = true
#trim_outliers = false
#remove_outliers = false
#embedding_dim = 16
#p_dropout = 0.0

[task]
type = 'link prediction'
seed = -1  # use < 0 for random
model_on_gpu = false
distmult_on_gpu = false
eval_interval = 10
filter_ranks = true
mrr_batch_size = 5e1
batchsize = -1  # < 0 for full batch

[model]
epoch = 20
learning_rate = 0.01
num_bases = 2
p_dropout = 0.0
weight_decay = 0.0
l1_lambda = 0.0
l2_lambda = 0.0
bias = false

[[model.layers]]
type = 'mrgcn'
hidden_nodes = 200
